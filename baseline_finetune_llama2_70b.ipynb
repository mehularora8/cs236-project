{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22569eee-fc2d-4598-9501-299c4c714d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/ovh/ai-training-examples/blob/main/notebooks/natural-language-processing/llm/miniconda/llama2-fine-tuning/llama_2_finetuning.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "197a176d-cf67-4225-8da3-aeb7c4222b4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate@ git+https://github.com/huggingface/accelerate.git (from -r requirements.txt (line 2))\n",
      "  Cloning https://github.com/huggingface/accelerate.git to /tmp/pip-install-20ayjasi/accelerate_86990736404a487db819ca8bb991b8a9\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /tmp/pip-install-20ayjasi/accelerate_86990736404a487db819ca8bb991b8a9\n",
      "  Resolved https://github.com/huggingface/accelerate.git to commit 44adf1e14fdacedd8a0f6984c878e5786772dd34\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transformers@ git+https://github.com/huggingface/transformers.git (from -r requirements.txt (line 5))\n",
      "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-install-20ayjasi/transformers_ee703d37ff8c4128bdfddf5bcbcfcce4\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-install-20ayjasi/transformers_ee703d37ff8c4128bdfddf5bcbcfcce4\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit 50573c648ae953dcc1b94d663651f07fb02268f4\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting peft@ git+https://github.com/huggingface/peft.git (from -r requirements.txt (line 6))\n",
      "  Cloning https://github.com/huggingface/peft.git to /tmp/pip-install-20ayjasi/peft_eca311e201a4418fa23b62c888dfde12\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-install-20ayjasi/peft_eca311e201a4418fa23b62c888dfde12\n",
      "  Resolved https://github.com/huggingface/peft.git to commit 140a69bb90fdb5c42d94f9d468916180e6027f55\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting trl@ git+https://github.com/lvwerra/trl.git (from -r requirements.txt (line 7))\n",
      "  Cloning https://github.com/lvwerra/trl.git to /tmp/pip-install-20ayjasi/trl_10b1ec82a17146f68be15878ea98d4f7\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/lvwerra/trl.git /tmp/pip-install-20ayjasi/trl_10b1ec82a17146f68be15878ea98d4f7\n",
      "  Resolved https://github.com/lvwerra/trl.git to commit d3bbee3ab84d4d5dcb413003bf93541df5b4e54c\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.0.1+cu118)\n",
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.41.1)\n",
      "Requirement already satisfied: datasets==2.13.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (2.13.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (1.11.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.1->-r requirements.txt (line 4)) (1.24.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.1->-r requirements.txt (line 4)) (13.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.1->-r requirements.txt (line 4)) (0.3.6)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.1->-r requirements.txt (line 4)) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.1->-r requirements.txt (line 4)) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.1->-r requirements.txt (line 4)) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.1->-r requirements.txt (line 4)) (3.3.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.1->-r requirements.txt (line 4)) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.1->-r requirements.txt (line 4)) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.1->-r requirements.txt (line 4)) (3.8.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.1->-r requirements.txt (line 4)) (0.16.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.1->-r requirements.txt (line 4)) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.1->-r requirements.txt (line 4)) (6.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->-r requirements.txt (line 1)) (3.25.0)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->-r requirements.txt (line 1)) (15.0.7)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate@ git+https://github.com/huggingface/accelerate.git->-r requirements.txt (line 2)) (5.9.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers@ git+https://github.com/huggingface/transformers.git->-r requirements.txt (line 5)) (2023.8.8)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers@ git+https://github.com/huggingface/transformers.git->-r requirements.txt (line 5)) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers@ git+https://github.com/huggingface/transformers.git->-r requirements.txt (line 5)) (0.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.1->-r requirements.txt (line 4)) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.1->-r requirements.txt (line 4)) (2.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.1->-r requirements.txt (line 4)) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.1->-r requirements.txt (line 4)) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.1->-r requirements.txt (line 4)) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.1->-r requirements.txt (line 4)) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.1->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.13.1->-r requirements.txt (line 4)) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.13.1->-r requirements.txt (line 4)) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.13.1->-r requirements.txt (line 4)) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 1)) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.13.1->-r requirements.txt (line 4)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.13.1->-r requirements.txt (line 4)) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.13.1->-r requirements.txt (line 4)) (2023.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 1)) (1.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.13.1->-r requirements.txt (line 4)) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3513302-e4dd-454b-8493-7d557ea1a7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f021975-90a3-4971-94e6-1bccda17ef8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import bitsandbytes as bnb\n",
    "from datasets import load_dataset\n",
    "from functools import partial\n",
    "import os\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, AutoPeftModelForCausalLM\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, set_seed, Trainer, TrainingArguments, BitsAndBytesConfig, \\\n",
    "    DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer\n",
    "\n",
    "from baseline_finetune_fxs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc726c19-1a82-42bb-ba6e-f1cd4b908aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-87f8d14ca6e1dabd/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87890dc276e94e17812185f7f9cea736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"csv\", data_files=[\"dataset.csv\"])['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87b75b3-f605-4d66-8a84-737cef311c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e980e4bc1c7346499189130e22ac64ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/610 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f37c7299e7040aeb670ccd24e410232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)fetensors.index.json:   0%|          | 0.00/33.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea7a33cd1dcb41019e19d018a9e1f7bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9462fb9628c4a3faef5cacab9046150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00003.safetensors:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# change model_name for different model\n",
    "model_size = '70b'\n",
    "model_name = f\"meta-llama/Llama-2-{model_size}-hf\" \n",
    "\n",
    "bnb_config = create_bnb_config()\n",
    "\n",
    "model, tokenizer = load_model(model_name, bnb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941d32d8-4c92-4f85-b377-5099a92ca1b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# change output_dir for new model\n",
    "output_dir = f\"outputs/baseline_llama2_{model_size}/finetuned_ckpt\"\n",
    "train(model, tokenizer, dataset, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fd15d3-3b4d-45a4-852a-3769f9a167d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge model w PEFT weights\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(output_dir, device_map=\"auto\", torch_dtype=torch.bfloat16)\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "# Save merged model\n",
    "output_merged_dir = f\"outputs/baseline_llama2_{model_size}/merged_ckpt\"\n",
    "\n",
    "os.makedirs(output_merged_dir, exist_ok=True)\n",
    "model.save_pretrained(output_merged_dir, safe_serialization=True)\n",
    "\n",
    "# Save tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.save_pretrained(output_merged_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8626aa5c-f598-4d6e-b474-119f3f6d31f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and tokenizer\n",
    "output_merged_dir = f\"outputs/baseline_llama2_{model_size}/merged_ckpt\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(output_merged_dir, device_map=\"auto\", torch_dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_merged_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b59d1b2-28ff-42ad-9d18-506692fdb732",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run inference here\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "with open('sys_prompt_zero.txt', 'r') as file:\n",
    "    prompt = file.read()\n",
    "    \n",
    "sequences = pipeline(\n",
    "    prompt,\n",
    "    max_length=4096,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744a176c-e657-4b0c-8c4d-b6b08b7627d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ''\n",
    "for seq in sequences:\n",
    "    output += (seq['generated_text'])\n",
    "    \n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb812be-6700-4698-abf5-bb3e41fa95eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
